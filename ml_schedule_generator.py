from transformers import T5Tokenizer, T5ForConditionalGeneration
import torch
import logging
import re
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Hugging Face model repo
model_name = "PrabathDamarla/visionary_schedule_model"

try:
    logger.info(f"â³ Loading visionary model from Hugging Face: {model_name}")
    tokenizer = T5Tokenizer.from_pretrained(model_name)
    model = T5ForConditionalGeneration.from_pretrained(model_name)
    model_loaded = True
    logger.info("âœ… Visionary model loaded successfully from Hugging Face.")
except Exception as e:
    logger.error(f"âŒ Failed to load T5 model from Hugging Face: {e}")
    model_loaded = False


def beautify_schedule(raw_output):
    today = datetime.now()
    formatted_date = today.strftime("%B %d")  # Example: August 13

    raw_output = raw_output.replace("Visionary Schedule", "").strip()

    blocks = re.findall(
        r"(\d{2}:\d{2}â€“\d{2}:\d{2})\s*â€“\s*(.*?)(?=(?:\d{2}:\d{2}â€“\d{2}:\d{2})|$)",
        raw_output
    )

    emoji_map = {
        "Morning Routine": "â˜€ï¸", "Physics": "âš›ï¸", "Science": "ğŸ”¬", "Chemistry": "ğŸ§ª",
        "Biology": "ğŸ§¬", "Math": "ğŸ“", "Breakfast": "ğŸ½ï¸", "Lunch": "ğŸ¥—", "Dinner": "ğŸ½ï¸",
        "Snacks": "ğŸª", "Nap": "ğŸ›ï¸", "Sleep": "ğŸ˜´", "Sleep Prep": "ğŸ˜´", "Break": "â˜•",
        "Tea Break": "ğŸµ", "Relax": "ğŸ§˜", "Meditation": "ğŸ§˜â€â™‚ï¸", "Exercise": "ğŸ‹ï¸â€â™€ï¸",
        "Light Walk": "ğŸš¶", "Walk": "ğŸš¶â€â™‚ï¸", "Mock Test": "ğŸ“", "Doubt Solving": "â“",
        "Revision": "ğŸ”", "Final Review": "âœ…", "Reading": "ğŸ“–", "Journaling": "ğŸ““",
        "Mindfulness": "ğŸ§ ", "YouTube": "ğŸ“º", "Instagram": "ğŸ“¸", "Pomodoro": "ğŸ…",
        "Productivity": "ğŸ’¡", "Focus": "ğŸ¯", "Call": "ğŸ“", "Meeting": "ğŸ“…"
    }

    clock_emojis = ["ğŸ•–", "ğŸ•—", "ğŸ•˜", "ğŸ•™", "ğŸ•š", "ğŸ•›", "ğŸ•", "ğŸ•‘", "ğŸ•’", "ğŸ•“", "ğŸ•”", "ğŸ••"]

    formatted = [f"ğŸ“… {formatted_date} â€” Visionary Schedule"]
    for i, (time, task) in enumerate(blocks):
        emoji = next((emoji_map[key] for key in emoji_map if key.lower() in task.lower()), "")
        clock = clock_emojis[i % len(clock_emojis)]
        formatted.append(f"{clock} {time} â€“ {task.strip()} {emoji}")

    return "\n".join(formatted)


def generate_schedule(prompt_text):
    if not model_loaded:
        return "âŒ Visionary model not loaded."

    try:
        input_text = f"Generate schedule: {prompt_text}"
        inputs = tokenizer(input_text, return_tensors="pt").to(model.device)

        outputs = model.generate(
            **inputs,
            max_new_tokens=300,
            do_sample=True,
            top_k=50,
            top_p=0.95,
            temperature=0.9,
            repetition_penalty=1.2,
            num_beams=1,
        )

        raw_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(raw_text)

        return beautify_schedule(raw_text)

    except Exception as e:
        logger.error(f"âŒ Exception during generation: {e}")
        return "âŒ Error generating schedule."
